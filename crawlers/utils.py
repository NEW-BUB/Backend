# pip install newspaper3k lxml_html_clean
from newspaper import Article 
import re
from .keyword import *
def get_news(url):
    
    def clean_text(text):
        lines = text.split('\n')
        cleaned_lines = []

        for line in lines:
            line = line.strip()
            if not line:
                continue  # ë¹ˆ ì¤„ ì œê±°

            # ì¤„ ì „ì²´ ì œê±° ì¡°ê±´ ì¶”ê°€: VOD ì•ˆë‚´, ë¸Œë¼ìš°ì € ì—…ê·¸ë ˆì´ë“œ ë“± ì•ˆë‚´ ë¬¸êµ¬ ì œê±°
            if re.search(r'(VOD ì‹œì²­ ì•ˆë‚´|ì–´ë„ë¹„ í”Œë˜ì‹œ í”Œë ˆì´ì–´|ë¸Œë¼ìš°ì € ì—…ê·¸ë ˆì´ë“œ|ì„œë¹„ìŠ¤ê°€ ì›í• í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤)', line):
                continue

            # ì¤„ ì „ì²´ ì œê±° ì¡°ê±´: 'ì „ê²½.', 'ëª¨ìŠµ.', 'â“’' í¬í•¨
            if re.search(r'(â“’|Â©|[ì „ê²½|ëª¨ìŠµ]\.)', line):
                continue  # ì¤„ ìì²´ ì œê±°

            # ë¶€ë¶„ ì œê±° ì¡°ê±´: ê¸°ì ì´ë¦„, ì´ë©”ì¼, ì¢‹ì•„ìš” ë“±
            line = re.sub(r'[ê°€-í£]+ ?ê¸°ì', '', line)  # ê¸°ì ì´ë¦„
            line = re.sub(r'[\w\.-]+@[\w\.-]+', '', line)  # ì´ë©”ì¼
            line = re.sub(r'(ì‘ì›ìˆ˜|ì¢‹ì•„ìš”|ì¶”ì²œìˆ˜|ì´ë¯¸ì§€ í™•ëŒ€|ë‹«ê¸°)[^\n]*', '', line)  # ì¢‹ì•„ìš”, ì‘ì›ìˆ˜ ë“±

            cleaned_lines.append(line.strip())

        return '\n'.join(cleaned_lines).strip()

    
    # ë¶ˆìš©ì–´ ë° ì œì™¸ ì¡°ê±´
    stopwords = [
        "ì‘ê°€ì˜", "ì´ì•¼ê¸°", "í¬í•¨í•œ", "ìµœëŒ€", "ë§¤ì¼", "ì¶œì‹œ", "êµ­ë‚´", "ì •ë§ë¡œ", 
        "ì‚¬ì‹¤", "ë³´ë„ì— ë”°ë¥´ë©´", "ì¶œì²˜", "ê¸°ì", "ê²°êµ­", "ë”°ë¼ì„œ","ì¦‰", "ê·¸ë˜ì„œ", 
        "ê²°ê³¼ì ìœ¼ë¡œ", "ê²€ìƒ‰", "ë¬¸ì œ", "ì¦ê¸¸", "ë†€ëŸ¬", "ë‚˜ë“¤", "ì—´ë¦°", "ë„˜ì–´"
    ]

    print(f"\nğŸ“° ê¸°ì‚¬ URL: {url}")

    try:
        article = Article(url, language='ko')
        article.download()
        article.parse()

        title = article.title
        date = article.publish_date
        image = article.top_image
        authors = article.authors
        text = clean_text(article.text)

        print("ì œëª©:", title)
        print("ë°œí–‰ì¼:", date)
        print("ëŒ€í‘œ ì´ë¯¸ì§€ URL:", image)
        if authors: print("ì‘ì„±ì:", authors)
        print("ë³¸ë¬¸ ì¼ë¶€:", text[:100], "...")
        # print("ì›ë˜ ë³¸ë¬¸:", article.text)
        print("ë³€ê²½ëœ ë³¸ë¬¸:", text)
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        print("\n=== ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´ í‚¤ì›Œë“œ ì¶”ì¶œ ===")
        keywords1 = get_keyword(text, stopwords, 2)
        for keyword, score in keywords1:
            print(f"{keyword}: {score}")
        
        print("\n=== kiwië¥¼ ì´ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ ===")
        keywords2 = extract_keywords_with_kiwi(text, top_n=10)
        for keyword, count in keywords2:
            print(f"{keyword}: {count}íšŒ")

        print("\n=== KKMA í‚¤ì›Œë“œ ì¶”ì¶œ ===")
        keywords3 = extract_keywords_with_kkma(text, top_n=10)
        for keyword, count in keywords3:
            print(f"{keyword}: {count}íšŒ")
    except Exception as e:
        print("ê¸°ì‚¬ ì²˜ë¦¬ ì‹¤íŒ¨:", e)