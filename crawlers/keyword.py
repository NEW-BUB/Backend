import re
from collections import Counter
from soynlp.word import WordExtractor
from soynlp.noun import LRNounExtractor

def extract_keywords(text, top_n=10):
    """
    í•œêµ­ì–´ í…ìŠ¤íŠ¸ì—ì„œ ëª…ì‚¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (soynlp ì‚¬ìš©)

    Args:
        text (str): í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  í…ìŠ¤íŠ¸
        top_n (int): ë°˜í™˜í•  ìƒìœ„ í‚¤ì›Œë“œ ê°œìˆ˜

    Returns:
        list: (í‚¤ì›Œë“œ, ë¹ˆë„ìˆ˜) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
    """
    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
    text = text.lower()  # ì†Œë¬¸ì ë³€í™˜
    text = re.sub(r'[^\w\s]', ' ', text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°

    # í•œêµ­ì–´ ë¶ˆìš©ì–´ ëª©ë¡ (í•„ìš”ì— ë”°ë¼ í™•ì¥ ê°€ëŠ¥)
    stopwords = [
        'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ì´ê²ƒ', 'ê·¸ê²ƒ', 'ì €ê²ƒ',
        'ë‚˜', 'ë„ˆ', 'ìš°ë¦¬', 'ë‹¹ì‹ ', 'ê·¸ë“¤', 'ì €í¬', 'ìê¸°',
        'ì´ëŸ°', 'ê·¸ëŸ°', 'ì €ëŸ°', 'ì´ë ‡ê²Œ', 'ê·¸ë ‡ê²Œ', 'ì €ë ‡ê²Œ',
        'ë°', 'ì—', 'ì˜', 'ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì€', 'ëŠ”',
        'ë¡œ', 'ìœ¼ë¡œ', 'ì—ì„œ', 'ì—ê²Œ', 'í•œí…Œ', 'ê»˜', 'ì™€', 'ê³¼',
        'ì´ë‚˜', 'ë‚˜', 'ë‘', 'í•˜ê³ ', 'ê¹Œì§€', 'ë¶€í„°', 'ë„', 'ë§Œ',
        'ë°', 'ê°™ì€', 'ê°™ì´', 'ì²˜ëŸ¼', 'ë³´ë‹¤', 'ë¼ê³ ', 'í•˜ë‹¤', 'ì„',
        'ìˆë‹¤', 'ì—†ë‹¤', 'ë˜ë‹¤', 'í•˜ë‹¤', 'ë•Œë¬¸', 'ë•Œ', 'ë‚´', 'ê·¸ëƒ¥'
    ]

    # ëª…ì‚¬ ì¶”ì¶œê¸° í•™ìŠµ (ë¬¸ì„œê°€ ì¶©ë¶„íˆ í¬ë‹¤ë©´ ì‚¬ìš©)
    if len(text) > 500:  # í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„íˆ ê¸´ ê²½ìš°ì—ë§Œ í•™ìŠµ
        noun_extractor = LRNounExtractor()
        nouns = noun_extractor.extract([text])
        nouns = nouns.keys()
    else:
        # í…ìŠ¤íŠ¸ê°€ ì§§ì€ ê²½ìš° WordExtractor ì‚¬ìš©
        word_extractor = WordExtractor()
        words = word_extractor.extract([text]).keys()

        # ëª…ì‚¬ í›„ë³´ í•„í„°ë§ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        nouns = []
        for word in words:
            if len(word) > 1 and not any(char.isdigit() for char in word):
                nouns.append(word)

    # ë‹¨ì¼ ê¸€ì ëª…ì‚¬ì™€ ë¶ˆìš©ì–´ ì œê±°
    filtered_nouns = [noun for noun in nouns if noun not in stopwords and len(noun) > 1]

    # ë¹ˆë„ìˆ˜ ê³„ì‚°
    noun_counter = Counter(filtered_nouns)

    # ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
    top_keywords = noun_counter.most_common(top_n)

    return top_keywords


def get_keyword(text, stopwords=None, count=1):
    """
    í•œêµ­ì–´ í…ìŠ¤íŠ¸ì—ì„œ ëª…ì‚¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (krwordrank.word ì‚¬ìš©)

    Args:
        text (str): í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  í…ìŠ¤íŠ¸
        stopwords (list): í‚¤ì›Œë“œ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸íŠ¸
        count (list): ì¶”ì¶œí•  í‚¤ì›Œë“œì˜ ìµœì†Œ ë¹ˆë„ íšŸìˆ˜

    Returns:
        list: (í‚¤ì›Œë“œ, ì ìˆ˜) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
    """
    try:
        from krwordrank.word import summarize_with_keywords
        import pandas as pd

        # ğŸ”¸ ê¸°ë³¸ ë¶ˆìš©ì–´ ì„¤ì •
        stopwords += [
            'ìˆë‹¤', 'í•œë‹¤', 'ìœ„í•´', 'ëŒ€í•œ', 'í†µí•´', 'ë°', 'ë“±', 'ì œ', 'ì˜', 'ìˆëŠ”',
            'í•˜ë©°', 'í•˜ê³ ', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ê·¸ë¦¬ê³ ', 'ê·¸', 'ìœ„í•œ', 'ë„ë‚´', 'ì´ì „',
            'ì§€ë‚œ', 'ë‚´ë…„', 'ìˆìŒì„', 'ê·¸ëŠ”', 'í•˜ëŠ”', 'ê·¸ì˜', 'ì´í›„', 'í–ˆë‹¤', 'ê·¸ë…€',
            'ì €', 'ì´ëŸ°', 'ìµœê·¼', 'ë•Œë¬¸', 'ê´€ë ¨', 'ë‹¤ë¥¸', 'í•œ', 'ì´ë‹¤', 'í•˜ë‹¤', 'ì„',
            'ë¥¼', 'ì´', 'ê°€', 'ë“¤', 'ì™€', 'ê³¼', 'íŠ¹íˆ', 'ì¶œì‹œ', 'êµ­ë‚´', 'ìµœì‹ ', 'í•¨ê»˜',
            'ê°™ì´', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜', 'ë”°ë¼ì„œ', 'ê²Œë‹¤ê°€', 'ë˜ëŠ”', 'ë¿ë§Œ ì•„ë‹ˆë¼',
            'ì´ë¼ë©´', 'ì´ë¼ì„œ', 'ì˜€ìœ¼ë©°', 'í–ˆë˜', 'ë•Œë¬¸ì—', 'ë“±ì„', 'ì˜í•´', 'ìœ¼ë¡œì¨',
            'ë§¤ìš°', 'êµ‰ì¥íˆ', 'ì•„ì£¼', 'ì˜', 'ì¡°ê¸ˆ', 'ì¢€', 'ê°™ì€', 'ì •ë§', 'ë§ì€', 'ëª¨ë“ ',
            'ì„œë¡œ', 'ì˜¤ëŠ˜', 'ë‚´ì¼', 'ì–´ì œ', 'ì§€ê¸ˆ', 'í˜„ì¬', 'ë‹¤ê°€ì˜¤ëŠ”', 'ì•ìœ¼ë¡œ', 'ì§€ë‚œë²ˆ',
            'ì˜¬í•´', 'ìš°ë¦¬', 'ë„ˆí¬', 'ë„ˆ', 'ì €í¬', 'ìì‹ ', 'ëˆ„êµ¬', 'ê°ì', 'ëª¨ë“  ì‚¬ëŒ',
            'ì‚¬ëŒë“¤', 'ê·¸ê²ƒ', 'ì–´ë–»ê²Œ', 'ë¬´ì—‡', 'ì™œ', 'ë‹¤ì‹œ', 'ê±°ê¸°', 'ì €ê¸°', 'ì—¬ê¸°', 'ê±°ì˜',
            'ëŒ€ë¶€ë¶„', 'ë‹¹ì‹œ', 'ê·¸ë‚ ', 'ë‹¤ìŒ', 'ê·¸ë•Œ', 'ì´ë²ˆ', 'ì–¸ì œë‚˜', 'í•­ìƒ', 'ìì£¼',
            'ê°€ë”', 'ì¢…ì¢…', 'í•œë²ˆ', 'ì •ë„', 'ì•½ê°„', 'ëŒ€ëµ', 'ì™„ì „íˆ', 'ì „í˜€', 'ë”ë¶ˆì–´',
            'ì‹¬ì§€ì–´', 'ë”êµ¬ë‚˜', 'í™•ì‹¤íˆ', 'ë¶„ëª…íˆ', 'ìˆë‹¤ê³ ', 'ê°€ìš´ë°', 'ì˜¤í›„', 'ì´ë¼ë©°',
            'ì´ë¼', 'ê²½ìš°', 'ê²°ê³¼', 'ì´ë‹¬', 'ìˆì–´', 'ëŒ€í•´', 'ê¸°ì¡´', 'í–¥í›„', 'ë¹„ë¡¯'
        ]

        # âœ… í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        text = text.lower()  # ëª¨ë“  ë¬¸ìë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜
        text = re.sub(r'[^ê°€-í£a-z\s]', ' ', text)  # í•œê¸€, ì˜ë¬¸, ê³µë°±ë§Œ ë‚¨ê¹€

        # âœ… ë¬¸ì¥ ë¶„ë¦¬ ë° ì •ë¦¬
        sentences = re.split(r'[.\n]', text)
        sentences = [s.strip() for s in sentences if len(s.strip()) > 10]

        # âœ… í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = summarize_with_keywords(
            sentences,
            min_count=count,
            max_length=10,
            beta=0.85,
            max_iter=20
        )

        filtered_keywords = {
            k: v for k, v in keywords.items()
            if not re.match(r'.*(ë‹¤|ì´ë‹¤|ìˆë‹¤|í•œë‹¤|í–ˆë‹¤|í•˜ë‹¤|ë³´ë‹¤|í•œ|ë¥¼|ë |ì„|ì´|ê°€|ì˜|ì€|ëŠ”|ë¡œ|ê¹Œì§€|ì—|ê²Œ|ì |ê³ |ë©°|ë©´|ì„œ|ë¶€í„°)$', k)  # ì¡°ì‚¬/ì–´ë¯¸ë¡œ ëë‚˜ëŠ” í‚¤ì›Œë“œ ì œê±°
        }

        # ğŸ”¸ DataFrame ë³€í™˜
        df = pd.DataFrame(
            sorted(filtered_keywords.items(), key=lambda x: -x[1]),
            columns=['Keyword', 'Score']
        )

        # ë¶ˆìš©ì–´ ì œê±°: 'Keyword' ì»¬ëŸ¼ì—ì„œ ë¶ˆìš©ì–´ë¥¼ ì œì™¸í•œ ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        df['Keyword'] = df['Keyword'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))

        # ë¶ˆìš©ì–´ë¥¼ ì œì™¸í•œ í‚¤ì›Œë“œë§Œ ë‚¨ê¸°ê¸° (ë¶ˆìš©ì–´ê°€ í¬í•¨ëœ í‚¤ì›Œë“œëŠ” ì œê±°ë¨)
        df = df[df['Keyword'].str.strip() != '']

        return df.head(20).values.tolist()
    
    except ImportError:
        print("krwordrank.word ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. pip install krwordrank.wordë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        return []


# Kiwi
def extract_keywords_with_kiwi(text, top_n=10):
    """
    í•œêµ­ì–´ í…ìŠ¤íŠ¸ì—ì„œ ëª…ì‚¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (kiwipiepy ì‚¬ìš©)

    Args:
        text (str): í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  í…ìŠ¤íŠ¸
        top_n (int): ë°˜í™˜í•  ìƒìœ„ í‚¤ì›Œë“œ ê°œìˆ˜

    Returns:
        list: (í‚¤ì›Œë“œ, ë¹ˆë„ìˆ˜) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
    """
    try:
        from kiwipiepy import Kiwi

        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        text = text.lower()  # ì†Œë¬¸ì ë³€í™˜
        text = re.sub(r'[^\w\s]', ' ', text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°

        # ë¶ˆìš©ì–´ ëª©ë¡ì€ ìœ„ì™€ ë™ì¼
        stopwords = [
            'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ì´ê²ƒ', 'ê·¸ê²ƒ', 'ì €ê²ƒ',
            'ë‚˜', 'ë„ˆ', 'ìš°ë¦¬', 'ë‹¹ì‹ ', 'ê·¸ë“¤', 'ì €í¬', 'ìê¸°',
            'ì´ëŸ°', 'ê·¸ëŸ°', 'ì €ëŸ°', 'ì´ë ‡ê²Œ', 'ê·¸ë ‡ê²Œ', 'ì €ë ‡ê²Œ',
            'ë°', 'ì—', 'ì˜', 'ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì€', 'ëŠ”',
            'ë¡œ', 'ìœ¼ë¡œ', 'ì—ì„œ', 'ì—ê²Œ', 'í•œí…Œ', 'ê»˜', 'ì™€', 'ê³¼',
            'ì´ë‚˜', 'ë‚˜', 'ë‘', 'í•˜ê³ ', 'ê¹Œì§€', 'ë¶€í„°', 'ë„', 'ë§Œ',
            'ë°', 'ê°™ì€', 'ê°™ì´', 'ì²˜ëŸ¼', 'ë³´ë‹¤', 'ë¼ê³ ', 'í•˜ë‹¤', 'ì„',
            'ìˆë‹¤', 'ì—†ë‹¤', 'ë˜ë‹¤', 'í•˜ë‹¤', 'ë•Œë¬¸', 'ë•Œ', 'ë‚´', 'ê·¸ëƒ¥'
        ]

        # Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
        kiwi = Kiwi()

        # í…ìŠ¤íŠ¸ ë¶„ì„ ë° ëª…ì‚¬ ì¶”ì¶œ
        result = kiwi.analyze(text)
        nouns = []

        for token in result[0][0]:
            if token.tag in ['NNG', 'NNP']:  # ì¼ë°˜ ëª…ì‚¬ì™€ ê³ ìœ  ëª…ì‚¬ë§Œ ì¶”ì¶œ
                nouns.append(token.form)

        # ë‹¨ì¼ ê¸€ì ëª…ì‚¬ì™€ ë¶ˆìš©ì–´ ì œê±°
        filtered_nouns = [noun for noun in nouns if noun not in stopwords and len(noun) > 1]

        # ë¹ˆë„ìˆ˜ ê³„ì‚°
        noun_counter = Counter(filtered_nouns)

        # ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
        top_keywords = noun_counter.most_common(top_n)

        return top_keywords

    except ImportError:
        print("kiwipiepy ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. pip install kiwipiepyë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        return []


# KKMA
def extract_keywords_with_kkma(text, top_n=10):
    """
    KKMA í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•œ ëª…ì‚¬ í‚¤ì›Œë“œ ì¶”ì¶œ

    Args:
        text (str): í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  í…ìŠ¤íŠ¸
        top_n (int): ë°˜í™˜í•  ìƒìœ„ í‚¤ì›Œë“œ ê°œìˆ˜

    Returns:
        list: (í‚¤ì›Œë“œ, ë¹ˆë„ìˆ˜) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
    """
    try:
        from konlpy.tag import Kkma

        kkma = Kkma()

        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        text = text.lower()
        text = re.sub(r'[^\w\sê°€-í£]', ' ', text)

        # ë¶ˆìš©ì–´ ëª©ë¡ (ê¸°ì¡´ê³¼ ë™ì¼)
        stopwords = [
            'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ì´ê²ƒ', 'ê·¸ê²ƒ', 'ì €ê²ƒ',
            'ë‚˜', 'ë„ˆ', 'ìš°ë¦¬', 'ë‹¹ì‹ ', 'ê·¸ë“¤', 'ì €í¬', 'ìê¸°',
            'ì´ëŸ°', 'ê·¸ëŸ°', 'ì €ëŸ°', 'ì´ë ‡ê²Œ', 'ê·¸ë ‡ê²Œ', 'ì €ë ‡ê²Œ',
            'ë°', 'ì—', 'ì˜', 'ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì€', 'ëŠ”',
            'ë¡œ', 'ìœ¼ë¡œ', 'ì—ì„œ', 'ì—ê²Œ', 'í•œí…Œ', 'ê»˜', 'ì™€', 'ê³¼',
            'ì´ë‚˜', 'ë‚˜', 'ë‘', 'í•˜ê³ ', 'ê¹Œì§€', 'ë¶€í„°', 'ë„', 'ë§Œ',
            'ë°', 'ê°™ì€', 'ê°™ì´', 'ì²˜ëŸ¼', 'ë³´ë‹¤', 'ë¼ê³ ', 'í•˜ë‹¤', 'ì„',
            'ìˆë‹¤', 'ì—†ë‹¤', 'ë˜ë‹¤', 'í•˜ë‹¤', 'ë•Œë¬¸', 'ë•Œ', 'ë‚´', 'ê·¸ëƒ¥'
        ]

        # ëª…ì‚¬ ì¶”ì¶œ
        nouns = kkma.nouns(text)

        # í•„í„°ë§
        filtered_nouns = [noun for noun in nouns if noun not in stopwords and len(noun) > 1]

        # ë¹ˆë„ìˆ˜ ê³„ì‚°
        noun_counter = Counter(filtered_nouns)
        return noun_counter.most_common(top_n)

    except ImportError:
        print("konlpy ë˜ëŠ” KKMAê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. pip install konlpyë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        return []